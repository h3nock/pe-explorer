# Synthetic Data Generation Config

content_sampling:
  digit: 0.5
  char: 0.5

tasks:
  passkey:
    weight: 0.20
    code_len: [1, 5]
    depths:
      train: [0.25, 0.5, 0.75, 1.0]
      eval_id: [0.25, 0.5, 0.75, 1.0]
      eval_ood: [1.5, 2.0]

  copy_distance:
    weight: 0.25
    content_len: 5
    depths:
      train: [0.25, 0.5, 0.75, 1.0]
      eval_id: [0.25, 0.5, 0.75, 1.0]
      eval_ood: [1.5, 2.0]

  reverse:
    weight: 0.18
    length:
      train: [3, 8]
      eval_id: [3, 8]
      eval_ood: [9, 16]

  sort:
    weight: 0.17
    length:
      train: [3, 6]
      eval_id: [3, 6]
      eval_ood: [7, 10]

  no_carry_add:
    weight: 0.12
    digits: [0, 4]
    length:
      train: [2, 5]
      eval_id: [2, 5]
      eval_ood: [6, 8]

  simple_copy:
    weight: 0.08
    length:
      train: [4, 12]
      eval_id: [4, 12]
      eval_ood: [13, 20]

filler:
  pool_path: "data/filler_pool.parquet"
  context_len: 1024
  eval_context_len: 2048

generation:
  output_dir: data/algorithmic
  train_seed: 42
  eval_seed: 123
  default_train_examples: 1000000  # total synthetic training examples
  default_eval_per_task: 1000      # eval examples per task (split id/ood)
  shard_size: 250000               # examples per output parquet file
